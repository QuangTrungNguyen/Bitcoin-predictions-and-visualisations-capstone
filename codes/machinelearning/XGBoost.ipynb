{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 36\n",
      "n_samples: 2735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volatility</th>\n",
       "      <th>volume</th>\n",
       "      <th>google_trends</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>platinum</th>\n",
       "      <th>palladium</th>\n",
       "      <th>oil</th>\n",
       "      <th>usd_eur</th>\n",
       "      <th>...</th>\n",
       "      <th>TXN_per_block</th>\n",
       "      <th>est_TXN_vol</th>\n",
       "      <th>cost_per_TXN</th>\n",
       "      <th>total_TXN_fees</th>\n",
       "      <th>usd_trade_vol</th>\n",
       "      <th>hash_rate</th>\n",
       "      <th>avg_block_size</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>num_unique_addr</th>\n",
       "      <th>miners_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>6093.67</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>3.279760e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1260.30</td>\n",
       "      <td>16.225</td>\n",
       "      <td>864.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>75.23</td>\n",
       "      <td>1.1672</td>\n",
       "      <td>...</td>\n",
       "      <td>1274.987261</td>\n",
       "      <td>675604827.0</td>\n",
       "      <td>61.446716</td>\n",
       "      <td>213583.5164</td>\n",
       "      <td>501623219.9</td>\n",
       "      <td>39627403.83</td>\n",
       "      <td>0.920948</td>\n",
       "      <td>5.080000e+12</td>\n",
       "      <td>415602</td>\n",
       "      <td>1.209255e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>6157.13</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>3.296220e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1254.60</td>\n",
       "      <td>16.210</td>\n",
       "      <td>860.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>77.41</td>\n",
       "      <td>1.1616</td>\n",
       "      <td>...</td>\n",
       "      <td>1338.383562</td>\n",
       "      <td>609799528.3</td>\n",
       "      <td>59.349571</td>\n",
       "      <td>201953.0378</td>\n",
       "      <td>363193880.4</td>\n",
       "      <td>36850961.53</td>\n",
       "      <td>1.067592</td>\n",
       "      <td>5.080000e+12</td>\n",
       "      <td>410397</td>\n",
       "      <td>1.139519e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>5903.44</td>\n",
       "      <td>0.049391</td>\n",
       "      <td>3.467800e+09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1251.55</td>\n",
       "      <td>16.110</td>\n",
       "      <td>852.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>73.45</td>\n",
       "      <td>1.1583</td>\n",
       "      <td>...</td>\n",
       "      <td>1557.933884</td>\n",
       "      <td>795615808.3</td>\n",
       "      <td>50.289212</td>\n",
       "      <td>197368.2529</td>\n",
       "      <td>345979167.6</td>\n",
       "      <td>30540865.37</td>\n",
       "      <td>1.088043</td>\n",
       "      <td>5.080000e+12</td>\n",
       "      <td>397865</td>\n",
       "      <td>9.288788e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>6218.30</td>\n",
       "      <td>0.070443</td>\n",
       "      <td>3.966230e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1250.45</td>\n",
       "      <td>16.030</td>\n",
       "      <td>851.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>74.13</td>\n",
       "      <td>1.1658</td>\n",
       "      <td>...</td>\n",
       "      <td>1195.057325</td>\n",
       "      <td>703945479.4</td>\n",
       "      <td>65.127555</td>\n",
       "      <td>166798.5735</td>\n",
       "      <td>262900494.4</td>\n",
       "      <td>39627403.83</td>\n",
       "      <td>0.689430</td>\n",
       "      <td>5.080000e+12</td>\n",
       "      <td>396405</td>\n",
       "      <td>1.205269e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>6404.00</td>\n",
       "      <td>0.039642</td>\n",
       "      <td>4.543860e+09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1250.45</td>\n",
       "      <td>16.030</td>\n",
       "      <td>851.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>74.13</td>\n",
       "      <td>1.1658</td>\n",
       "      <td>...</td>\n",
       "      <td>1310.470199</td>\n",
       "      <td>656285943.9</td>\n",
       "      <td>57.609894</td>\n",
       "      <td>163181.8222</td>\n",
       "      <td>414797814.1</td>\n",
       "      <td>38112980.76</td>\n",
       "      <td>0.746513</td>\n",
       "      <td>5.080000e+12</td>\n",
       "      <td>453050</td>\n",
       "      <td>1.123672e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        close  volatility        volume  google_trends     gold  silver  \\\n",
       "2730  6093.67    0.031736  3.279760e+09            6.0  1260.30  16.225   \n",
       "2731  6157.13    0.020789  3.296220e+09            6.0  1254.60  16.210   \n",
       "2732  5903.44    0.049391  3.467800e+09            6.0  1251.55  16.110   \n",
       "2733  6218.30    0.070443  3.966230e+09            8.0  1250.45  16.030   \n",
       "2734  6404.00    0.039642  4.543860e+09            7.0  1250.45  16.030   \n",
       "\n",
       "      platinum  palladium    oil  usd_eur       ...        TXN_per_block  \\\n",
       "2730     864.0      939.0  75.23   1.1672       ...          1274.987261   \n",
       "2731     860.0      946.0  77.41   1.1616       ...          1338.383562   \n",
       "2732     852.0      945.0  73.45   1.1583       ...          1557.933884   \n",
       "2733     851.0      953.0  74.13   1.1658       ...          1195.057325   \n",
       "2734     851.0      953.0  74.13   1.1658       ...          1310.470199   \n",
       "\n",
       "      est_TXN_vol  cost_per_TXN  total_TXN_fees  usd_trade_vol    hash_rate  \\\n",
       "2730  675604827.0     61.446716     213583.5164    501623219.9  39627403.83   \n",
       "2731  609799528.3     59.349571     201953.0378    363193880.4  36850961.53   \n",
       "2732  795615808.3     50.289212     197368.2529    345979167.6  30540865.37   \n",
       "2733  703945479.4     65.127555     166798.5735    262900494.4  39627403.83   \n",
       "2734  656285943.9     57.609894     163181.8222    414797814.1  38112980.76   \n",
       "\n",
       "      avg_block_size    difficulty  num_unique_addr  miners_revenue  \n",
       "2730        0.920948  5.080000e+12           415602    1.209255e+07  \n",
       "2731        1.067592  5.080000e+12           410397    1.139519e+07  \n",
       "2732        1.088043  5.080000e+12           397865    9.288788e+06  \n",
       "2733        0.689430  5.080000e+12           396405    1.205269e+07  \n",
       "2734        0.746513  5.080000e+12           453050    1.123672e+07  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from spark_sklearn import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from time import time\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, LinearRegression, ElasticNetCV, LassoCV, Lasso, Ridge, RidgeCV, BayesianRidge, ARDRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('final.csv')\n",
    "data = data.drop(columns=['date','low','open','high','marketcap'])\n",
    "#data = data[data.columns[sel]]\n",
    "print('n_features:', len(data.iloc[0]))\n",
    "print('n_samples:', len(data))\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 36\n",
      "n_samples: 92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volatility</th>\n",
       "      <th>volume</th>\n",
       "      <th>google_trends</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>platinum</th>\n",
       "      <th>palladium</th>\n",
       "      <th>oil</th>\n",
       "      <th>usd_eur</th>\n",
       "      <th>...</th>\n",
       "      <th>TXN_per_block</th>\n",
       "      <th>est_TXN_vol</th>\n",
       "      <th>cost_per_TXN</th>\n",
       "      <th>total_TXN_fees</th>\n",
       "      <th>usd_trade_vol</th>\n",
       "      <th>hash_rate</th>\n",
       "      <th>avg_block_size</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>num_unique_addr</th>\n",
       "      <th>miners_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6385.82</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>4788259840</td>\n",
       "      <td>62</td>\n",
       "      <td>1250.45</td>\n",
       "      <td>16.030</td>\n",
       "      <td>851.0</td>\n",
       "      <td>953</td>\n",
       "      <td>74.13</td>\n",
       "      <td>1.1658</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.148936</td>\n",
       "      <td>493208885.1</td>\n",
       "      <td>58.735614</td>\n",
       "      <td>140545.4062</td>\n",
       "      <td>489427084.1</td>\n",
       "      <td>35588942.30</td>\n",
       "      <td>0.987340</td>\n",
       "      <td>5.077500e+12</td>\n",
       "      <td>368307</td>\n",
       "      <td>10494418.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6614.18</td>\n",
       "      <td>0.058242</td>\n",
       "      <td>4396930048</td>\n",
       "      <td>72</td>\n",
       "      <td>1247.80</td>\n",
       "      <td>15.980</td>\n",
       "      <td>839.0</td>\n",
       "      <td>941</td>\n",
       "      <td>73.89</td>\n",
       "      <td>1.1639</td>\n",
       "      <td>...</td>\n",
       "      <td>1062.904762</td>\n",
       "      <td>991949405.1</td>\n",
       "      <td>75.393733</td>\n",
       "      <td>106682.7087</td>\n",
       "      <td>224327884.6</td>\n",
       "      <td>37103365.37</td>\n",
       "      <td>0.705291</td>\n",
       "      <td>5.077500e+12</td>\n",
       "      <td>341861</td>\n",
       "      <td>11673361.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6529.59</td>\n",
       "      <td>0.034094</td>\n",
       "      <td>4672309760</td>\n",
       "      <td>69</td>\n",
       "      <td>1251.75</td>\n",
       "      <td>15.930</td>\n",
       "      <td>838.0</td>\n",
       "      <td>954</td>\n",
       "      <td>74.19</td>\n",
       "      <td>1.1665</td>\n",
       "      <td>...</td>\n",
       "      <td>1413.432624</td>\n",
       "      <td>720058629.1</td>\n",
       "      <td>57.309569</td>\n",
       "      <td>150160.0866</td>\n",
       "      <td>281178824.1</td>\n",
       "      <td>37594816.26</td>\n",
       "      <td>0.987550</td>\n",
       "      <td>5.172890e+12</td>\n",
       "      <td>433257</td>\n",
       "      <td>11271293.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6597.55</td>\n",
       "      <td>0.048633</td>\n",
       "      <td>4176689920</td>\n",
       "      <td>65</td>\n",
       "      <td>1255.65</td>\n",
       "      <td>16.045</td>\n",
       "      <td>834.0</td>\n",
       "      <td>948</td>\n",
       "      <td>74.19</td>\n",
       "      <td>1.1665</td>\n",
       "      <td>...</td>\n",
       "      <td>1868.508621</td>\n",
       "      <td>872392592.0</td>\n",
       "      <td>45.224241</td>\n",
       "      <td>185064.5374</td>\n",
       "      <td>356469308.6</td>\n",
       "      <td>30929068.69</td>\n",
       "      <td>1.113817</td>\n",
       "      <td>5.363680e+12</td>\n",
       "      <td>456149</td>\n",
       "      <td>9617154.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6639.14</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>4999240192</td>\n",
       "      <td>69</td>\n",
       "      <td>1255.50</td>\n",
       "      <td>15.950</td>\n",
       "      <td>845.5</td>\n",
       "      <td>947</td>\n",
       "      <td>73.05</td>\n",
       "      <td>1.1709</td>\n",
       "      <td>...</td>\n",
       "      <td>1543.194030</td>\n",
       "      <td>665699858.5</td>\n",
       "      <td>54.318173</td>\n",
       "      <td>142640.2951</td>\n",
       "      <td>345023639.3</td>\n",
       "      <td>35728406.94</td>\n",
       "      <td>0.935353</td>\n",
       "      <td>5.363680e+12</td>\n",
       "      <td>435401</td>\n",
       "      <td>11089706.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     close  volatility      volume  google_trends     gold  silver  platinum  \\\n",
       "0  6385.82    0.022569  4788259840             62  1250.45  16.030     851.0   \n",
       "1  6614.18    0.058242  4396930048             72  1247.80  15.980     839.0   \n",
       "2  6529.59    0.034094  4672309760             69  1251.75  15.930     838.0   \n",
       "3  6597.55    0.048633  4176689920             65  1255.65  16.045     834.0   \n",
       "4  6639.14    0.030521  4999240192             69  1255.50  15.950     845.5   \n",
       "\n",
       "   palladium    oil  usd_eur       ...        TXN_per_block  est_TXN_vol  \\\n",
       "0        953  74.13   1.1658       ...          1284.148936  493208885.1   \n",
       "1        941  73.89   1.1639       ...          1062.904762  991949405.1   \n",
       "2        954  74.19   1.1665       ...          1413.432624  720058629.1   \n",
       "3        948  74.19   1.1665       ...          1868.508621  872392592.0   \n",
       "4        947  73.05   1.1709       ...          1543.194030  665699858.5   \n",
       "\n",
       "   cost_per_TXN  total_TXN_fees  usd_trade_vol    hash_rate  avg_block_size  \\\n",
       "0     58.735614     140545.4062    489427084.1  35588942.30        0.987340   \n",
       "1     75.393733     106682.7087    224327884.6  37103365.37        0.705291   \n",
       "2     57.309569     150160.0866    281178824.1  37594816.26        0.987550   \n",
       "3     45.224241     185064.5374    356469308.6  30929068.69        1.113817   \n",
       "4     54.318173     142640.2951    345023639.3  35728406.94        0.935353   \n",
       "\n",
       "     difficulty  num_unique_addr  miners_revenue  \n",
       "0  5.077500e+12           368307     10494418.50  \n",
       "1  5.077500e+12           341861     11673361.88  \n",
       "2  5.172890e+12           433257     11271293.25  \n",
       "3  5.363680e+12           456149      9617154.00  \n",
       "4  5.363680e+12           435401     11089706.00  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('Test_Data.csv')\n",
    "test_data = test_data.drop(columns=['date','low','open','high','marketcap'])\n",
    "print('n_features:', len(test_data.iloc[0]))\n",
    "print('n_samples:', len(test_data))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 37\n",
      "n_samples: 214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatility</th>\n",
       "      <th>volume</th>\n",
       "      <th>google_trends</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>platinum</th>\n",
       "      <th>palladium</th>\n",
       "      <th>oil</th>\n",
       "      <th>usd_eur</th>\n",
       "      <th>usd_jpy</th>\n",
       "      <th>...</th>\n",
       "      <th>est_TXN_vol</th>\n",
       "      <th>cost_per_TXN</th>\n",
       "      <th>total_TXN_fees</th>\n",
       "      <th>usd_trade_vol</th>\n",
       "      <th>hash_rate</th>\n",
       "      <th>avg_block_size</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>num_unique_addr</th>\n",
       "      <th>miners_revenue</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.034161</td>\n",
       "      <td>4.726180e+09</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1201.90</td>\n",
       "      <td>14.290</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>73.40</td>\n",
       "      <td>1.1777</td>\n",
       "      <td>0.00905</td>\n",
       "      <td>...</td>\n",
       "      <td>503494967.4</td>\n",
       "      <td>52.112921</td>\n",
       "      <td>102965.2698</td>\n",
       "      <td>273203917.3</td>\n",
       "      <td>52622781.21</td>\n",
       "      <td>0.807114</td>\n",
       "      <td>7.152630e+12</td>\n",
       "      <td>469028</td>\n",
       "      <td>12385677.98</td>\n",
       "      <td>6495.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.028964</td>\n",
       "      <td>4.437300e+09</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1194.25</td>\n",
       "      <td>14.475</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>72.22</td>\n",
       "      <td>1.1737</td>\n",
       "      <td>0.00904</td>\n",
       "      <td>...</td>\n",
       "      <td>842041019.0</td>\n",
       "      <td>54.247914</td>\n",
       "      <td>130284.3136</td>\n",
       "      <td>390313648.8</td>\n",
       "      <td>60089527.19</td>\n",
       "      <td>0.768241</td>\n",
       "      <td>7.152630e+12</td>\n",
       "      <td>490588</td>\n",
       "      <td>13676604.30</td>\n",
       "      <td>6676.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.037517</td>\n",
       "      <td>4.606810e+09</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1185.40</td>\n",
       "      <td>14.420</td>\n",
       "      <td>812.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>72.18</td>\n",
       "      <td>1.1707</td>\n",
       "      <td>0.00905</td>\n",
       "      <td>...</td>\n",
       "      <td>748444892.4</td>\n",
       "      <td>46.610199</td>\n",
       "      <td>130238.5658</td>\n",
       "      <td>312748554.4</td>\n",
       "      <td>49422747.22</td>\n",
       "      <td>0.898005</td>\n",
       "      <td>7.152630e+12</td>\n",
       "      <td>474079</td>\n",
       "      <td>11369486.09</td>\n",
       "      <td>6644.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.027904</td>\n",
       "      <td>5.014430e+09</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1187.25</td>\n",
       "      <td>14.305</td>\n",
       "      <td>815.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>73.16</td>\n",
       "      <td>1.1576</td>\n",
       "      <td>0.00906</td>\n",
       "      <td>...</td>\n",
       "      <td>824319235.8</td>\n",
       "      <td>47.597177</td>\n",
       "      <td>154586.9390</td>\n",
       "      <td>283381555.4</td>\n",
       "      <td>50844984.55</td>\n",
       "      <td>0.877031</td>\n",
       "      <td>7.152630e+12</td>\n",
       "      <td>481907</td>\n",
       "      <td>11836751.48</td>\n",
       "      <td>6601.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.019986</td>\n",
       "      <td>4.363690e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1187.25</td>\n",
       "      <td>14.305</td>\n",
       "      <td>815.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>73.16</td>\n",
       "      <td>1.1576</td>\n",
       "      <td>0.00902</td>\n",
       "      <td>...</td>\n",
       "      <td>913410388.9</td>\n",
       "      <td>51.317781</td>\n",
       "      <td>193097.0923</td>\n",
       "      <td>457654461.3</td>\n",
       "      <td>54756137.20</td>\n",
       "      <td>0.855169</td>\n",
       "      <td>7.152630e+12</td>\n",
       "      <td>527057</td>\n",
       "      <td>13046981.40</td>\n",
       "      <td>6625.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     volatility        volume  google_trends     gold  silver  platinum  \\\n",
       "208    0.034161  4.726180e+09           61.0  1201.90  14.290     827.0   \n",
       "209    0.028964  4.437300e+09           59.0  1194.25  14.475     824.0   \n",
       "210    0.037517  4.606810e+09           58.0  1185.40  14.420     812.0   \n",
       "211    0.027904  5.014430e+09           58.0  1187.25  14.305     815.0   \n",
       "212    0.019986  4.363690e+09           48.0  1187.25  14.305     815.0   \n",
       "\n",
       "     palladium    oil  usd_eur  usd_jpy   ...     est_TXN_vol  cost_per_TXN  \\\n",
       "208     1065.0  73.40   1.1777  0.00905   ...     503494967.4     52.112921   \n",
       "209     1059.0  72.22   1.1737  0.00904   ...     842041019.0     54.247914   \n",
       "210     1067.0  72.18   1.1707  0.00905   ...     748444892.4     46.610199   \n",
       "211     1094.0  73.16   1.1576  0.00906   ...     824319235.8     47.597177   \n",
       "212     1094.0  73.16   1.1576  0.00902   ...     913410388.9     51.317781   \n",
       "\n",
       "     total_TXN_fees  usd_trade_vol    hash_rate  avg_block_size    difficulty  \\\n",
       "208     102965.2698    273203917.3  52622781.21        0.807114  7.152630e+12   \n",
       "209     130284.3136    390313648.8  60089527.19        0.768241  7.152630e+12   \n",
       "210     130238.5658    312748554.4  49422747.22        0.898005  7.152630e+12   \n",
       "211     154586.9390    283381555.4  50844984.55        0.877031  7.152630e+12   \n",
       "212     193097.0923    457654461.3  54756137.20        0.855169  7.152630e+12   \n",
       "\n",
       "     num_unique_addr  miners_revenue    Price  \n",
       "208           469028     12385677.98  6495.00  \n",
       "209           490588     13676604.30  6676.75  \n",
       "210           474079     11369486.09  6644.13  \n",
       "211           481907     11836751.48  6601.96  \n",
       "212           527057     13046981.40  6625.56  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined train and test sets\n",
    "combined_data = pd.concat([data[2613:], test_data], ignore_index=True)\n",
    "combined_data['Price'] = combined_data['close'].shift(-1)\n",
    "print('n_features:', len(combined_data.iloc[0]))\n",
    "print('n_samples:', len(combined_data))\n",
    "combined_data = combined_data.iloc[:-1,1:]\n",
    "combined_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "def normalize_data(X,Y=None):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(X,Y)\n",
    "\n",
    "# Define time-series cross validation split\n",
    "def TimeSeriesCVSplit(n_samples, test_size, step_size):\n",
    "    data_split = []\n",
    "    train_end = n_samples - test_size - step_size \n",
    "    test_start = train_end + step_size\n",
    "    for i in range(0,test_size):\n",
    "        train_index = list(range(0, train_end))\n",
    "        test_index = [test_start]\n",
    "        data_split.append([train_index,test_index])\n",
    "        train_end+=1\n",
    "        test_start+=1\n",
    "    return data_split\n",
    "\n",
    "def wfss(X,Y,model,subset):\n",
    "    sel = subset.copy() # # Selected features\n",
    "    overall_error = train_model(X[:,sel],Y,model,predict=False) \n",
    "    while len(sel) != 0:\n",
    "        # Select candidate\n",
    "        cand_error = 1e10 # Assign a big number\n",
    "        for cand in sel:\n",
    "            features = sel.copy()\n",
    "            features.remove(cand)\n",
    "            if len(features) > 1:\n",
    "                new_error = train_model(X[:,features],Y,model,predict=False)\n",
    "            else:\n",
    "                new_error = train_model(X[:,features[0]].reshape(-1,1),Y,model,predict=False)\n",
    "            if new_error < cand_error:\n",
    "                selected_candidate = cand\n",
    "                cand_error = new_error\n",
    "        if overall_error < cand_error:\n",
    "            # Stop if the new candidate doesn’t\n",
    "            # improve the assessment of the\n",
    "            # previously selected candidates\n",
    "            break\n",
    "        else:\n",
    "            overall_error = cand_error\n",
    "            sel.remove(selected_candidate)\n",
    "    print('RMSE:', str(train_model(X[:,sel],Y,model,predict=False)))\n",
    "    return sel\n",
    "\n",
    "def train_model(X,Y,model,predict):\n",
    "    data_split = TimeSeriesCVSplit(len(X),n_validation,0)\n",
    "    Y_pred = []\n",
    "    Y_test = []\n",
    "    scores = []\n",
    "    n=1\n",
    "    for fold in data_split:\n",
    "        X_train = X[fold[0]]\n",
    "        Y_train = Y[fold[0]]\n",
    "        X_test = X[fold[1]]\n",
    "        y_pred = Y[fold[1]]\n",
    "        \n",
    "        import timeit\n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        if predict:\n",
    "            #print(n)\n",
    "            #Fine-tune alpha\n",
    "            #k, p, weights = fine_tune_KNN(X_train,Y_train)\n",
    "                # Feature Selection\n",
    "            selected_features = wfss(X_train,Y_train,model,np.arange(0,35).tolist())         \n",
    "            print(n, selected_features)\n",
    "            \n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X_train[:,selected_features],Y_train)\n",
    "            X_train = scaler.transform(X_train[:,selected_features])\n",
    "            X_test = scaler.transform(X_test[:,selected_features])  \n",
    "            \n",
    "        if not predict:\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X_train,Y_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test) \n",
    "        \n",
    "        \n",
    "        model.fit(X_train,Y_train.reshape(-1,))\n",
    "        prediction = model.predict(X_test).reshape(-1,1)\n",
    "        Y_pred.append(prediction)\n",
    "        Y_test.append(y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred, prediction))\n",
    "        scores.append(rmse)\n",
    "        \n",
    "        if predict:\n",
    "            stop = timeit.default_timer()\n",
    "            print('Time: ', stop - start)\n",
    "        n+=1\n",
    "    Y_pred = np.asarray(Y_pred)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "    if predict:\n",
    "        return np.sqrt(mean_squared_error(Y_pred.reshape(-1,1), Y_test.reshape(-1,1))), Y_test, Y_pred\n",
    "    if not predict:\n",
    "        return np.sqrt(mean_squared_error(Y_pred.reshape(-1,1), Y_test.reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "def get_feature_ranking(feature_scores):\n",
    "    indices = np.nonzero(feature_scores)[0].tolist()\n",
    "    scores = np.abs(feature_scores[indices]).tolist() \n",
    "    sorted_scores, sorted_features = zip(*sorted(zip(scores, indices),reverse=True))\n",
    "    return list(sorted_features)\n",
    "\n",
    "def RMSE(y_true, y_hat):\n",
    "    error = np.sqrt(mean_squared_error(y_true, y_hat))\n",
    "    return error\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Subsets\n",
    "lasso_subset = [34, 28, 30, 32, 1, 27, 2, 8, 25, 12, 22, 0, 17, 6, 18, 24, 9, 5, 31, 10, 19, 33, 23, 14] # lasso [0:20] for KNN\n",
    "\n",
    "### TO BE UPDATED ###\n",
    "etrees_subset = [34, 32, 14, 18, 27, 22, 1, 6, 23, 30, 16, 15, 19, 29, 28, 13, 26, 7, 8, 11, 2, 33, 3] # extra trees\n",
    "#subset4 = [0, 1, 24, 2, 31, 3, 29, 27, 34, 28, 7, 25, 26, 33, 4, 8, 6, 11, 17, 21, 30, 23, 22] # xgboost can remove 9\n",
    "xgb_subset = [0, 1, 29, 31, 27, 6, 28, 24, 25, 34, 7, 2, 8, 3, 26, 22, 4, 11, 21, 33, 20, 30, 17] # xgboost can remove 9\n",
    "subsets = [lasso_subset,etrees_subset,xgb_subset]\n",
    "\n",
    "# Validation samples size (1/4/18 - 30/6/18)\n",
    "n_validation = 91\n",
    "\n",
    "data = combined_data.values # use best period\n",
    "\n",
    "n_samples = len(data)\n",
    "Y = data[:-92,-1].reshape(-1,1)\n",
    "X = data[:-92,:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalize', MinMaxScaler(copy=True, feature_range=(0, 1))), ('xgb', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = pipe = Pipeline([\n",
    "    ('normalize', MinMaxScaler()),\n",
    "    ('xgb', XGBRegressor())\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 91 folds for each of 270 candidates, totalling 24570 fits\n",
      "Best Parameters:  {'xgb__booster': 'gbtree', 'xgb__gamma': 3, 'xgb__learning_rate': 0.15, 'xgb__max_depth': 3, 'xgb__n_estimators': 115, 'xgb__n_jobs': -1, 'xgb__reg_alpha': 0, 'xgb__silent': True}\n",
      "CPU times: user 2.27 s, sys: 746 ms, total: 3.01 s\n",
      "Wall time: 21min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sc = SparkContext()\n",
    "\n",
    "param_grid = [{\n",
    "            \"xgb__silent\":[True],\n",
    "            \"xgb__learning_rate\": [0.25, 0.15, 0.1, 0.2, 0.3],\n",
    "            \"xgb__gamma\": [1,2,3],\n",
    "            \"xgb__max_depth\": [3, 5, 10],\n",
    "            \"xgb__n_estimators\": [105,110,115],\n",
    "            \"xgb__reg_alpha\": [0,1],\n",
    "            \"xgb__n_jobs\": [-1],\n",
    "            \"xgb__booster\": [\"gbtree\"]\n",
    "} ]\n",
    "split = TimeSeriesCVSplit(len(X),n_validation,0)\n",
    "gs = GridSearchCV(sc, pipe, param_grid, cv=split, scoring=make_scorer(RMSE,greater_is_better=False), verbose=1) \n",
    "gs.fit(X,Y.reshape(-1,))\n",
    "print('Best Parameters: ',gs.cv_results_['params'][gs.best_index_])\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: -342.56379915006875\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE:\", str(gs.cv_results_['mean_test_score'][gs.best_index_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the best parameters from above into the XGBRegressor() below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
      "CPU times: user 9min 40s, sys: 3.08 s, total: 9min 43s\n",
      "Wall time: 10min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Feature Selection on Whole set\n",
    "selected_features = wfss(X,Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),np.arange(0,35).tolist())\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 319.7105023159526\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection on Whole Set\n",
    "sel = [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
    "rmse = train_model(X,Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=False)\n",
    "print('Train RMSE:',str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a12d5cbeec87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Feature Selection on Whole Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbtree'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m115\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ef2182502fae>\u001b[0m in \u001b[0;36mwfss\u001b[0;34m(X, Y, model, subset)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mnew_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mnew_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ef2182502fae>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, Y, model, predict)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[1;32m    322\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                               verbose_eval=verbose, xgb_model=xgb_model)\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1021\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Feature Selection on Whole Set\n",
    "sel = [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
    "selected_features = wfss(X,Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),np.arange(0,35).tolist())\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 429.64698468406425\n",
      "Train RMSE: 402.30792719193806\n"
     ]
    }
   ],
   "source": [
    "sel = [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
    "new_sel = [0, 1, 2, 3, 4, 6, 8, 9, 11, 15, 16, 17, 18, 21, 23, 26, 27, 30, 32, 33, 34]\n",
    "\n",
    "rmse = train_model(X[:,sel],Y,XGBRegressor(),predict=False)\n",
    "print('Train RMSE:',str(rmse))\n",
    "\n",
    "# Train Set\n",
    "n_validation = 91\n",
    "Y = data[:-92,-1].reshape(-1,1)\n",
    "X = data[:-92,:-1]\n",
    "selected_features=[0, 1, 2, 3, 4, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34]\n",
    "rmse,Y_test,Y_train_pred= train_model(X[:,selected_features],Y,XGBRegressor(),predict=True)\n",
    "print('Train RMSE:',str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 391.4651047830174\n",
      "[0, 1, 2, 3, 4, 6, 8, 9, 11, 15, 16, 17, 18, 21, 23, 26, 27, 30, 32, 33, 34]\n",
      "CPU times: user 2min 40s, sys: 716 ms, total: 2min 40s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selected_features = wfss(X,Y,XGBRegressor(),sel)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 448.941169363459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 29,\n",
       " 27,\n",
       " 30,\n",
       " 3,\n",
       " 6,\n",
       " 26,\n",
       " 34,\n",
       " 28,\n",
       " 31,\n",
       " 33,\n",
       " 15,\n",
       " 14,\n",
       " 11,\n",
       " 4,\n",
       " 2,\n",
       " 23,\n",
       " 22,\n",
       " 8,\n",
       " 24,\n",
       " 18,\n",
       " 7,\n",
       " 13,\n",
       " 5,\n",
       " 25,\n",
       " 32,\n",
       " 17,\n",
       " 16,\n",
       " 10,\n",
       " 9,\n",
       " 21,\n",
       " 12,\n",
       " 20]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE on whole set\n",
    "rmse = train_model(X,Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=False)\n",
    "print('Train RMSE:',str(rmse))\n",
    "xgb = XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True)\n",
    "Y = data[:-92,-1].reshape(-1,1)\n",
    "X = data[:-92,:-1]\n",
    "xgb.fit(X,Y.reshape(-1,))\n",
    "xgb_features = get_feature_ranking(xgb.feature_importances_)\n",
    "xgb_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 462.9408087710165\n"
     ]
    }
   ],
   "source": [
    "rmse = train_model(X,Y,XGBRegressor(),predict=False)\n",
    "print('Train RMSE:',str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 477.93429600898173\n",
      "Train RMSE: 437.65100376125724\n",
      "Train RMSE: 483.40974920998406\n"
     ]
    }
   ],
   "source": [
    "for subset in subsets:\n",
    "    rmse = train_model(X[:,subset],Y,XGBRegressor(),predict=False)\n",
    "    print('Train RMSE:',str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the best parameters from above into the XGBRegressor() below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 406.5415612855171\n",
      "1 [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34]\n",
      "Time:  436.71328531099425\n",
      "RMSE: 396.1515131528861\n",
      "2 [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
      "Time:  514.0519061109953\n",
      "RMSE: 395.03482271572926\n",
      "3 [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
      "Time:  503.134327820997\n",
      "RMSE: 385.6247639961619\n",
      "4 [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
      "Time:  569.273807058009\n",
      "RMSE: 394.87089264943137\n",
      "5 [0, 1, 3, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  586.62177431499\n",
      "RMSE: 395.82684960300963\n",
      "6 [0, 1, 3, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  593.2980180829909\n",
      "RMSE: 395.1525974302118\n",
      "7 [0, 1, 3, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  509.8208831189986\n",
      "RMSE: 394.5854261793568\n",
      "8 [0, 1, 3, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  505.17706278899277\n",
      "RMSE: 400.1106685432852\n",
      "9 [0, 1, 3, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  469.14372542800265\n",
      "RMSE: 382.413152257808\n",
      "10 [0, 1, 2, 3, 4, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  490.5353674000071\n",
      "RMSE: 390.8130589641836\n",
      "11 [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  364.0238766679977\n",
      "RMSE: 384.64719258927386\n",
      "12 [1, 2, 3, 5, 6, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  413.3692187379929\n",
      "RMSE: 383.67467107431435\n",
      "13 [1, 2, 3, 5, 6, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  429.4891437430051\n",
      "RMSE: 384.01884441652567\n",
      "14 [1, 2, 3, 5, 6, 9, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  467.80921097900136\n",
      "RMSE: 384.8685633605729\n",
      "15 [1, 2, 3, 5, 6, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "Time:  440.0239845979959\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test Set\n",
    "n_validation = 90\n",
    "Y = data[:,-1].reshape(-1,1)\n",
    "X = data[:,:-1]\n",
    "rmse,Y_test,Y_pred= train_model(X[:,:],Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=True)\n",
    "print('Test RMSE:',str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 448.941169363459\n",
      "Test RMSE: 319.7105023159526\n",
      "CPU times: user 5.67 s, sys: 31.5 ms, total: 5.7 s\n",
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selected_features = [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34]\n",
    "\n",
    "# Train Set\n",
    "n_validation = 91\n",
    "Y = data[:-92,-1].reshape(-1,1)\n",
    "X = data[:-92,:-1]\n",
    "rmse,Y_test,Y_train_pred= train_model(X[:,:],Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=True)\n",
    "print('Train RMSE:',str(rmse))\n",
    "\n",
    "# Test Set\n",
    "n_validation = 90\n",
    "Y = data[:,-1].reshape(-1,1)\n",
    "X = data[:,:-1]\n",
    "rmse,Y_test,Y_pred= train_model(X[:,:],Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=True)\n",
    "print('Test RMSE:',str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 423.03191736525815\n",
      "Test RMSE: 334.4979421670692\n",
      "CPU times: user 4.02 s, sys: 34.8 ms, total: 4.06 s\n",
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train Set\n",
    "n_validation = 91\n",
    "Y = data[:-92,-1].reshape(-1,1)\n",
    "X = data[:-92,:-1]\n",
    "rmse,Y_test,Y_train_pred= train_model(X[:,selected_features],Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=True)\n",
    "print('Train RMSE:',str(rmse))\n",
    "\n",
    "# Test Set\n",
    "n_validation = 90\n",
    "Y = data[:,-1].reshape(-1,1)\n",
    "X = data[:,:-1]\n",
    "rmse,Y_test,Y_pred= train_model(X[:,selected_features],Y,XGBRegressor(booster='gbtree',gamma=3,learning_rate=0.15,max_depth=3,n_estimators=115,n_jobs=-1,reg_alpha=0,silent=True),predict=True)\n",
    "print('Test RMSE:',str(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUAlIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "rgb(244, 146, 65)",
          "width": 2
         },
         "mode": "lines",
         "name": "Predicted labels",
         "type": "scatter",
         "uid": "2821098c-cd12-11e8-8916-88e9fe554462",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "y": [
          6591.90185546875,
          6480.67236328125,
          6470.15869140625,
          6464.5390625,
          6571.06884765625,
          6929.3056640625,
          6487.9931640625,
          6711.2705078125,
          6520.98095703125,
          6500.9873046875,
          6317.333984375,
          6267.244140625,
          6221.89990234375,
          6346.009765625,
          6562.72998046875,
          6970.80322265625,
          7469.791015625,
          6972.6875,
          7024.00390625,
          7075.21826171875,
          6769.4853515625,
          7938.02783203125,
          8008.61279296875,
          7809.54248046875,
          8125.74072265625,
          8015.00244140625,
          8214.24609375,
          7684.3369140625,
          8311.9189453125,
          7242.50048828125,
          7516.2373046875,
          7637.53466796875,
          7954.00048828125,
          7550.18408203125,
          7660.7099609375,
          7112.83642578125,
          6919.15673828125,
          6412.83544921875,
          6412.1318359375,
          6360.39990234375,
          6974.5341796875,
          6874.9013671875,
          6388.015625,
          6305.984375,
          6338.7822265625,
          6269.62841796875,
          6428.0703125,
          6358.3212890625,
          6198.22265625,
          6215.279296875,
          6448.734375,
          6477.61572265625,
          6342.10302734375,
          6609.376953125,
          6378.1025390625,
          6687.21533203125,
          7308.529296875,
          7499.53759765625,
          6731.86181640625,
          6863.81787109375,
          7040.70849609375,
          7199.9619140625,
          7279.7705078125,
          6800.53857421875,
          6930.025390625,
          6532.3896484375,
          6577.84765625,
          6753.56884765625,
          6367.06005859375,
          6406.1796875,
          6587.18701171875,
          6474.787109375,
          6405.0029296875,
          6635.51318359375,
          6458.21728515625,
          6779.71533203125,
          6684.01416015625,
          6556.22216796875,
          6726.97216796875,
          6450.5009765625,
          6558.11328125,
          7140.54443359375,
          6329.95556640625,
          6655.00830078125,
          6620.11767578125,
          6499.75732421875,
          6916.14794921875,
          6689.2490234375,
          6549.6337890625,
          6578.33544921875
         ]
        },
        {
         "line": {
          "color": "rgb(66, 244, 155)",
          "width": 2
         },
         "mode": "lines",
         "name": "True labels",
         "type": "scatter",
         "uid": "28210b50-cd12-11e8-9e0d-88e9fe554462",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "y": [
          6529.59,
          6597.55,
          6639.14,
          6673.5,
          6856.93,
          6773.88,
          6741.75,
          6329.95,
          6394.71,
          6228.81,
          6238.05,
          6276.12,
          6359.64,
          6741.75,
          7321.04,
          7370.78,
          7466.86,
          7354.13,
          7419.29,
          7418.49,
          7711.11,
          8424.27,
          8181.39,
          7951.58,
          8165.01,
          8192.15,
          8218.46,
          8180.48,
          7780.44,
          7624.91,
          7567.15,
          7434.39,
          7032.85,
          7068.48,
          6951.8,
          6753.12,
          6305.8,
          6568.23,
          6184.71,
          6295.73,
          6322.69,
          6297.57,
          6199.71,
          6308.52,
          6334.73,
          6580.63,
          6423.76,
          6506.07,
          6308.53,
          6488.76,
          6376.71,
          6534.88,
          6719.96,
          6763.19,
          6707.26,
          6884.64,
          7096.28,
          7047.16,
          6978.23,
          7037.58,
          7193.25,
          7272.72,
          7260.06,
          7361.66,
          6792.83,
          6529.17,
          6467.07,
          6225.98,
          6300.86,
          6329.7,
          6321.2,
          6351.8,
          6517.31,
          6512.71,
          6543.2,
          6517.18,
          6281.2,
          6371.3,
          6398.54,
          6519.67,
          6734.95,
          6721.98,
          6710.63,
          6595.41,
          6446.47,
          6495,
          6676.75,
          6644.13,
          6601.96,
          6625.56
         ]
        }
       ],
       "layout": {
        "title": "Comparison of true prices (on the test dataset) with prices our model predicted",
        "xaxis": {
         "title": "Day number"
        },
        "yaxis": {
         "title": "Price, USD"
        }
       }
      },
      "text/html": [
       "<div id=\"91a53f99-e221-4b6b-836c-62577efcff42\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"91a53f99-e221-4b6b-836c-62577efcff42\", [{\"line\": {\"color\": \"rgb(244, 146, 65)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Predicted labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6591.90185546875, 6480.67236328125, 6470.15869140625, 6464.5390625, 6571.06884765625, 6929.3056640625, 6487.9931640625, 6711.2705078125, 6520.98095703125, 6500.9873046875, 6317.333984375, 6267.244140625, 6221.89990234375, 6346.009765625, 6562.72998046875, 6970.80322265625, 7469.791015625, 6972.6875, 7024.00390625, 7075.21826171875, 6769.4853515625, 7938.02783203125, 8008.61279296875, 7809.54248046875, 8125.74072265625, 8015.00244140625, 8214.24609375, 7684.3369140625, 8311.9189453125, 7242.50048828125, 7516.2373046875, 7637.53466796875, 7954.00048828125, 7550.18408203125, 7660.7099609375, 7112.83642578125, 6919.15673828125, 6412.83544921875, 6412.1318359375, 6360.39990234375, 6974.5341796875, 6874.9013671875, 6388.015625, 6305.984375, 6338.7822265625, 6269.62841796875, 6428.0703125, 6358.3212890625, 6198.22265625, 6215.279296875, 6448.734375, 6477.61572265625, 6342.10302734375, 6609.376953125, 6378.1025390625, 6687.21533203125, 7308.529296875, 7499.53759765625, 6731.86181640625, 6863.81787109375, 7040.70849609375, 7199.9619140625, 7279.7705078125, 6800.53857421875, 6930.025390625, 6532.3896484375, 6577.84765625, 6753.56884765625, 6367.06005859375, 6406.1796875, 6587.18701171875, 6474.787109375, 6405.0029296875, 6635.51318359375, 6458.21728515625, 6779.71533203125, 6684.01416015625, 6556.22216796875, 6726.97216796875, 6450.5009765625, 6558.11328125, 7140.54443359375, 6329.95556640625, 6655.00830078125, 6620.11767578125, 6499.75732421875, 6916.14794921875, 6689.2490234375, 6549.6337890625, 6578.33544921875], \"type\": \"scatter\", \"uid\": \"28250f52-cd12-11e8-bac9-88e9fe554462\"}, {\"line\": {\"color\": \"rgb(66, 244, 155)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"True labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6529.59, 6597.55, 6639.14, 6673.5, 6856.93, 6773.88, 6741.75, 6329.95, 6394.71, 6228.81, 6238.05, 6276.12, 6359.64, 6741.75, 7321.04, 7370.78, 7466.86, 7354.13, 7419.29, 7418.49, 7711.11, 8424.27, 8181.39, 7951.58, 8165.01, 8192.15, 8218.46, 8180.48, 7780.44, 7624.91, 7567.15, 7434.39, 7032.85, 7068.48, 6951.8, 6753.12, 6305.8, 6568.23, 6184.71, 6295.73, 6322.69, 6297.57, 6199.71, 6308.52, 6334.73, 6580.63, 6423.76, 6506.07, 6308.53, 6488.76, 6376.71, 6534.88, 6719.96, 6763.19, 6707.26, 6884.64, 7096.28, 7047.16, 6978.23, 7037.58, 7193.25, 7272.72, 7260.06, 7361.66, 6792.83, 6529.17, 6467.07, 6225.98, 6300.86, 6329.7, 6321.2, 6351.8, 6517.31, 6512.71, 6543.2, 6517.18, 6281.2, 6371.3, 6398.54, 6519.67, 6734.95, 6721.98, 6710.63, 6595.41, 6446.47, 6495.0, 6676.75, 6644.13, 6601.96, 6625.56], \"type\": \"scatter\", \"uid\": \"28251088-cd12-11e8-815d-88e9fe554462\"}], {\"title\": \"Comparison of true prices (on the test dataset) with prices our model predicted\", \"xaxis\": {\"title\": \"Day number\"}, \"yaxis\": {\"title\": \"Price, USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"91a53f99-e221-4b6b-836c-62577efcff42\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"91a53f99-e221-4b6b-836c-62577efcff42\", [{\"line\": {\"color\": \"rgb(244, 146, 65)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Predicted labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6591.90185546875, 6480.67236328125, 6470.15869140625, 6464.5390625, 6571.06884765625, 6929.3056640625, 6487.9931640625, 6711.2705078125, 6520.98095703125, 6500.9873046875, 6317.333984375, 6267.244140625, 6221.89990234375, 6346.009765625, 6562.72998046875, 6970.80322265625, 7469.791015625, 6972.6875, 7024.00390625, 7075.21826171875, 6769.4853515625, 7938.02783203125, 8008.61279296875, 7809.54248046875, 8125.74072265625, 8015.00244140625, 8214.24609375, 7684.3369140625, 8311.9189453125, 7242.50048828125, 7516.2373046875, 7637.53466796875, 7954.00048828125, 7550.18408203125, 7660.7099609375, 7112.83642578125, 6919.15673828125, 6412.83544921875, 6412.1318359375, 6360.39990234375, 6974.5341796875, 6874.9013671875, 6388.015625, 6305.984375, 6338.7822265625, 6269.62841796875, 6428.0703125, 6358.3212890625, 6198.22265625, 6215.279296875, 6448.734375, 6477.61572265625, 6342.10302734375, 6609.376953125, 6378.1025390625, 6687.21533203125, 7308.529296875, 7499.53759765625, 6731.86181640625, 6863.81787109375, 7040.70849609375, 7199.9619140625, 7279.7705078125, 6800.53857421875, 6930.025390625, 6532.3896484375, 6577.84765625, 6753.56884765625, 6367.06005859375, 6406.1796875, 6587.18701171875, 6474.787109375, 6405.0029296875, 6635.51318359375, 6458.21728515625, 6779.71533203125, 6684.01416015625, 6556.22216796875, 6726.97216796875, 6450.5009765625, 6558.11328125, 7140.54443359375, 6329.95556640625, 6655.00830078125, 6620.11767578125, 6499.75732421875, 6916.14794921875, 6689.2490234375, 6549.6337890625, 6578.33544921875], \"type\": \"scatter\", \"uid\": \"28250f52-cd12-11e8-bac9-88e9fe554462\"}, {\"line\": {\"color\": \"rgb(66, 244, 155)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"True labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6529.59, 6597.55, 6639.14, 6673.5, 6856.93, 6773.88, 6741.75, 6329.95, 6394.71, 6228.81, 6238.05, 6276.12, 6359.64, 6741.75, 7321.04, 7370.78, 7466.86, 7354.13, 7419.29, 7418.49, 7711.11, 8424.27, 8181.39, 7951.58, 8165.01, 8192.15, 8218.46, 8180.48, 7780.44, 7624.91, 7567.15, 7434.39, 7032.85, 7068.48, 6951.8, 6753.12, 6305.8, 6568.23, 6184.71, 6295.73, 6322.69, 6297.57, 6199.71, 6308.52, 6334.73, 6580.63, 6423.76, 6506.07, 6308.53, 6488.76, 6376.71, 6534.88, 6719.96, 6763.19, 6707.26, 6884.64, 7096.28, 7047.16, 6978.23, 7037.58, 7193.25, 7272.72, 7260.06, 7361.66, 6792.83, 6529.17, 6467.07, 6225.98, 6300.86, 6329.7, 6321.2, 6351.8, 6517.31, 6512.71, 6543.2, 6517.18, 6281.2, 6371.3, 6398.54, 6519.67, 6734.95, 6721.98, 6710.63, 6595.41, 6446.47, 6495.0, 6676.75, 6644.13, 6601.96, 6625.56], \"type\": \"scatter\", \"uid\": \"28251088-cd12-11e8-815d-88e9fe554462\"}], {\"title\": \"Comparison of true prices (on the test dataset) with prices our model predicted\", \"xaxis\": {\"title\": \"Day number\"}, \"yaxis\": {\"title\": \"Price, USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319.7105023159526\n"
     ]
    }
   ],
   "source": [
    "trace1 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_pred), 1),\n",
    "    y = Y_pred.reshape(-1,),\n",
    "    mode = 'lines',\n",
    "    name = 'Predicted labels',\n",
    "    line = dict(color=('rgb(244, 146, 65)'), width=2)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_test), 1),\n",
    "    y = Y_test.reshape(-1,),\n",
    "    mode = 'lines',\n",
    "    name = 'True labels',\n",
    "    line = dict(color=('rgb(66, 244, 155)'), width=2)\n",
    ")\n",
    "\n",
    "layout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted',\n",
    "             xaxis = dict(title = 'Day number'), yaxis = dict(title = 'Price, USD'))\n",
    "fig = dict(data=[trace1, trace2], layout=layout)\n",
    "py.iplot(fig, filename='results_demonstrating0')\n",
    "\n",
    "print(np.sqrt(mean_squared_error(Y_test.reshape(-1,), Y_pred.reshape(-1,))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "rgb(244, 146, 65)",
          "width": 2
         },
         "mode": "lines",
         "name": "Predicted labels",
         "type": "scatter",
         "uid": "55333ae4-cc79-11e8-b006-88e9fe554462",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "y": [
          6408.17919921875,
          6555.396484375,
          6456.771484375,
          6424.13671875,
          6517.5244140625,
          6936.06494140625,
          6485.68017578125,
          6791.0302734375,
          6637.7724609375,
          6521.81494140625,
          6342.8837890625,
          6334.62939453125,
          6224.375,
          6325.57763671875,
          6491.7041015625,
          6973.90380859375,
          7391.3720703125,
          6930.064453125,
          7143.38671875,
          7058.1298828125,
          6761.75634765625,
          7731.9921875,
          7907.83740234375,
          7899.44873046875,
          7989.5302734375,
          8015.7314453125,
          7985.0390625,
          7662.419921875,
          8595.5615234375,
          7201.33984375,
          7645.79931640625,
          7593.3330078125,
          7552.46875,
          7604.25,
          7605.9609375,
          7302.384765625,
          6681.13330078125,
          6676.93701171875,
          6412.0966796875,
          6479.91259765625,
          7074.13134765625,
          6929.82666015625,
          6565.21142578125,
          6595.8447265625,
          6345.86083984375,
          6301.97998046875,
          6463.68115234375,
          6374.60791015625,
          6362.31201171875,
          6333.83349609375,
          6286.84326171875,
          6575.18115234375,
          6340.57763671875,
          6503.28125,
          6539.2021484375,
          6708.72216796875,
          7365.0322265625,
          7660.24462890625,
          6942.607421875,
          6798.92919921875,
          7132.77197265625,
          7128.7861328125,
          7284.46484375,
          7027.89013671875,
          6999.884765625,
          6533.0302734375,
          6629.63037109375,
          6635.30810546875,
          6346.6162109375,
          6574.82568359375,
          6565.30419921875,
          6513.51708984375,
          6523.791015625,
          6801.767578125,
          6534.22705078125,
          6660.04541015625,
          6705.7978515625,
          6729.48681640625,
          6834.14013671875,
          6440.5791015625,
          6533.8203125,
          7172.39208984375,
          6292.423828125,
          6605.875,
          6637.65771484375,
          6510.2060546875,
          6854.576171875,
          6636.66064453125,
          6614.5869140625,
          6623.3359375
         ]
        },
        {
         "line": {
          "color": "rgb(66, 244, 155)",
          "width": 2
         },
         "mode": "lines",
         "name": "True labels",
         "type": "scatter",
         "uid": "55333cba-cc79-11e8-b0ba-88e9fe554462",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "y": [
          6529.59,
          6597.55,
          6639.14,
          6673.5,
          6856.93,
          6773.88,
          6741.75,
          6329.95,
          6394.71,
          6228.81,
          6238.05,
          6276.12,
          6359.64,
          6741.75,
          7321.04,
          7370.78,
          7466.86,
          7354.13,
          7419.29,
          7418.49,
          7711.11,
          8424.27,
          8181.39,
          7951.58,
          8165.01,
          8192.15,
          8218.46,
          8180.48,
          7780.44,
          7624.91,
          7567.15,
          7434.39,
          7032.85,
          7068.48,
          6951.8,
          6753.12,
          6305.8,
          6568.23,
          6184.71,
          6295.73,
          6322.69,
          6297.57,
          6199.71,
          6308.52,
          6334.73,
          6580.63,
          6423.76,
          6506.07,
          6308.53,
          6488.76,
          6376.71,
          6534.88,
          6719.96,
          6763.19,
          6707.26,
          6884.64,
          7096.28,
          7047.16,
          6978.23,
          7037.58,
          7193.25,
          7272.72,
          7260.06,
          7361.66,
          6792.83,
          6529.17,
          6467.07,
          6225.98,
          6300.86,
          6329.7,
          6321.2,
          6351.8,
          6517.31,
          6512.71,
          6543.2,
          6517.18,
          6281.2,
          6371.3,
          6398.54,
          6519.67,
          6734.95,
          6721.98,
          6710.63,
          6595.41,
          6446.47,
          6495,
          6676.75,
          6644.13,
          6601.96,
          6625.56
         ]
        }
       ],
       "layout": {
        "title": "Comparison of true prices (on the test dataset) with prices our model predicted",
        "xaxis": {
         "title": "Day number"
        },
        "yaxis": {
         "title": "Price, USD"
        }
       }
      },
      "text/html": [
       "<div id=\"7f837311-7e7c-4a14-9df2-ce06898b8a84\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7f837311-7e7c-4a14-9df2-ce06898b8a84\", [{\"line\": {\"color\": \"rgb(244, 146, 65)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Predicted labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6408.17919921875, 6555.396484375, 6456.771484375, 6424.13671875, 6517.5244140625, 6936.06494140625, 6485.68017578125, 6791.0302734375, 6637.7724609375, 6521.81494140625, 6342.8837890625, 6334.62939453125, 6224.375, 6325.57763671875, 6491.7041015625, 6973.90380859375, 7391.3720703125, 6930.064453125, 7143.38671875, 7058.1298828125, 6761.75634765625, 7731.9921875, 7907.83740234375, 7899.44873046875, 7989.5302734375, 8015.7314453125, 7985.0390625, 7662.419921875, 8595.5615234375, 7201.33984375, 7645.79931640625, 7593.3330078125, 7552.46875, 7604.25, 7605.9609375, 7302.384765625, 6681.13330078125, 6676.93701171875, 6412.0966796875, 6479.91259765625, 7074.13134765625, 6929.82666015625, 6565.21142578125, 6595.8447265625, 6345.86083984375, 6301.97998046875, 6463.68115234375, 6374.60791015625, 6362.31201171875, 6333.83349609375, 6286.84326171875, 6575.18115234375, 6340.57763671875, 6503.28125, 6539.2021484375, 6708.72216796875, 7365.0322265625, 7660.24462890625, 6942.607421875, 6798.92919921875, 7132.77197265625, 7128.7861328125, 7284.46484375, 7027.89013671875, 6999.884765625, 6533.0302734375, 6629.63037109375, 6635.30810546875, 6346.6162109375, 6574.82568359375, 6565.30419921875, 6513.51708984375, 6523.791015625, 6801.767578125, 6534.22705078125, 6660.04541015625, 6705.7978515625, 6729.48681640625, 6834.14013671875, 6440.5791015625, 6533.8203125, 7172.39208984375, 6292.423828125, 6605.875, 6637.65771484375, 6510.2060546875, 6854.576171875, 6636.66064453125, 6614.5869140625, 6623.3359375], \"type\": \"scatter\", \"uid\": \"553a142c-cc79-11e8-b933-88e9fe554462\"}, {\"line\": {\"color\": \"rgb(66, 244, 155)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"True labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6529.59, 6597.55, 6639.14, 6673.5, 6856.93, 6773.88, 6741.75, 6329.95, 6394.71, 6228.81, 6238.05, 6276.12, 6359.64, 6741.75, 7321.04, 7370.78, 7466.86, 7354.13, 7419.29, 7418.49, 7711.11, 8424.27, 8181.39, 7951.58, 8165.01, 8192.15, 8218.46, 8180.48, 7780.44, 7624.91, 7567.15, 7434.39, 7032.85, 7068.48, 6951.8, 6753.12, 6305.8, 6568.23, 6184.71, 6295.73, 6322.69, 6297.57, 6199.71, 6308.52, 6334.73, 6580.63, 6423.76, 6506.07, 6308.53, 6488.76, 6376.71, 6534.88, 6719.96, 6763.19, 6707.26, 6884.64, 7096.28, 7047.16, 6978.23, 7037.58, 7193.25, 7272.72, 7260.06, 7361.66, 6792.83, 6529.17, 6467.07, 6225.98, 6300.86, 6329.7, 6321.2, 6351.8, 6517.31, 6512.71, 6543.2, 6517.18, 6281.2, 6371.3, 6398.54, 6519.67, 6734.95, 6721.98, 6710.63, 6595.41, 6446.47, 6495.0, 6676.75, 6644.13, 6601.96, 6625.56], \"type\": \"scatter\", \"uid\": \"553a160c-cc79-11e8-bafa-88e9fe554462\"}], {\"title\": \"Comparison of true prices (on the test dataset) with prices our model predicted\", \"xaxis\": {\"title\": \"Day number\"}, \"yaxis\": {\"title\": \"Price, USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7f837311-7e7c-4a14-9df2-ce06898b8a84\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7f837311-7e7c-4a14-9df2-ce06898b8a84\", [{\"line\": {\"color\": \"rgb(244, 146, 65)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Predicted labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6408.17919921875, 6555.396484375, 6456.771484375, 6424.13671875, 6517.5244140625, 6936.06494140625, 6485.68017578125, 6791.0302734375, 6637.7724609375, 6521.81494140625, 6342.8837890625, 6334.62939453125, 6224.375, 6325.57763671875, 6491.7041015625, 6973.90380859375, 7391.3720703125, 6930.064453125, 7143.38671875, 7058.1298828125, 6761.75634765625, 7731.9921875, 7907.83740234375, 7899.44873046875, 7989.5302734375, 8015.7314453125, 7985.0390625, 7662.419921875, 8595.5615234375, 7201.33984375, 7645.79931640625, 7593.3330078125, 7552.46875, 7604.25, 7605.9609375, 7302.384765625, 6681.13330078125, 6676.93701171875, 6412.0966796875, 6479.91259765625, 7074.13134765625, 6929.82666015625, 6565.21142578125, 6595.8447265625, 6345.86083984375, 6301.97998046875, 6463.68115234375, 6374.60791015625, 6362.31201171875, 6333.83349609375, 6286.84326171875, 6575.18115234375, 6340.57763671875, 6503.28125, 6539.2021484375, 6708.72216796875, 7365.0322265625, 7660.24462890625, 6942.607421875, 6798.92919921875, 7132.77197265625, 7128.7861328125, 7284.46484375, 7027.89013671875, 6999.884765625, 6533.0302734375, 6629.63037109375, 6635.30810546875, 6346.6162109375, 6574.82568359375, 6565.30419921875, 6513.51708984375, 6523.791015625, 6801.767578125, 6534.22705078125, 6660.04541015625, 6705.7978515625, 6729.48681640625, 6834.14013671875, 6440.5791015625, 6533.8203125, 7172.39208984375, 6292.423828125, 6605.875, 6637.65771484375, 6510.2060546875, 6854.576171875, 6636.66064453125, 6614.5869140625, 6623.3359375], \"type\": \"scatter\", \"uid\": \"553a142c-cc79-11e8-b933-88e9fe554462\"}, {\"line\": {\"color\": \"rgb(66, 244, 155)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"True labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6529.59, 6597.55, 6639.14, 6673.5, 6856.93, 6773.88, 6741.75, 6329.95, 6394.71, 6228.81, 6238.05, 6276.12, 6359.64, 6741.75, 7321.04, 7370.78, 7466.86, 7354.13, 7419.29, 7418.49, 7711.11, 8424.27, 8181.39, 7951.58, 8165.01, 8192.15, 8218.46, 8180.48, 7780.44, 7624.91, 7567.15, 7434.39, 7032.85, 7068.48, 6951.8, 6753.12, 6305.8, 6568.23, 6184.71, 6295.73, 6322.69, 6297.57, 6199.71, 6308.52, 6334.73, 6580.63, 6423.76, 6506.07, 6308.53, 6488.76, 6376.71, 6534.88, 6719.96, 6763.19, 6707.26, 6884.64, 7096.28, 7047.16, 6978.23, 7037.58, 7193.25, 7272.72, 7260.06, 7361.66, 6792.83, 6529.17, 6467.07, 6225.98, 6300.86, 6329.7, 6321.2, 6351.8, 6517.31, 6512.71, 6543.2, 6517.18, 6281.2, 6371.3, 6398.54, 6519.67, 6734.95, 6721.98, 6710.63, 6595.41, 6446.47, 6495.0, 6676.75, 6644.13, 6601.96, 6625.56], \"type\": \"scatter\", \"uid\": \"553a160c-cc79-11e8-bafa-88e9fe554462\"}], {\"title\": \"Comparison of true prices (on the test dataset) with prices our model predicted\", \"xaxis\": {\"title\": \"Day number\"}, \"yaxis\": {\"title\": \"Price, USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.4979421670692\n"
     ]
    }
   ],
   "source": [
    "trace1 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_pred), 1),\n",
    "    y = Y_pred.reshape(-1,),\n",
    "    mode = 'lines',\n",
    "    name = 'Predicted labels',\n",
    "    line = dict(color=('rgb(244, 146, 65)'), width=2)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_test), 1),\n",
    "    y = Y_test.reshape(-1,),\n",
    "    mode = 'lines',\n",
    "    name = 'True labels',\n",
    "    line = dict(color=('rgb(66, 244, 155)'), width=2)\n",
    ")\n",
    "\n",
    "layout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted',\n",
    "             xaxis = dict(title = 'Day number'), yaxis = dict(title = 'Price, USD'))\n",
    "fig = dict(data=[trace1, trace2], layout=layout)\n",
    "py.iplot(fig, filename='results_demonstrating0')\n",
    "\n",
    "print(np.sqrt(mean_squared_error(Y_test.reshape(-1,), Y_pred.reshape(-1,))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot shifted -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "rgb(244, 146, 65)",
          "width": 2
         },
         "mode": "lines",
         "name": "Predicted labels",
         "type": "scatter",
         "uid": "57197d46-cc79-11e8-9ecb-88e9fe554462",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "y": [
          6456.771484375,
          6424.13671875,
          6517.5244140625,
          6936.06494140625,
          6485.68017578125,
          6791.0302734375,
          6637.7724609375,
          6521.81494140625,
          6342.8837890625,
          6334.62939453125,
          6224.375,
          6325.57763671875,
          6491.7041015625,
          6973.90380859375,
          7391.3720703125,
          6930.064453125,
          7143.38671875,
          7058.1298828125,
          6761.75634765625,
          7731.9921875,
          7907.83740234375,
          7899.44873046875,
          7989.5302734375,
          8015.7314453125,
          7985.0390625,
          7662.419921875,
          8595.5615234375,
          7201.33984375,
          7645.79931640625,
          7593.3330078125,
          7552.46875,
          7604.25,
          7605.9609375,
          7302.384765625,
          6681.13330078125,
          6676.93701171875,
          6412.0966796875,
          6479.91259765625,
          7074.13134765625,
          6929.82666015625,
          6565.21142578125,
          6595.8447265625,
          6345.86083984375,
          6301.97998046875,
          6463.68115234375,
          6374.60791015625,
          6362.31201171875,
          6333.83349609375,
          6286.84326171875,
          6575.18115234375,
          6340.57763671875,
          6503.28125,
          6539.2021484375,
          6708.72216796875,
          7365.0322265625,
          7660.24462890625,
          6942.607421875,
          6798.92919921875,
          7132.77197265625,
          7128.7861328125,
          7284.46484375,
          7027.89013671875,
          6999.884765625,
          6533.0302734375,
          6629.63037109375,
          6635.30810546875,
          6346.6162109375,
          6574.82568359375,
          6565.30419921875,
          6513.51708984375,
          6523.791015625,
          6801.767578125,
          6534.22705078125,
          6660.04541015625,
          6705.7978515625,
          6729.48681640625,
          6834.14013671875,
          6440.5791015625,
          6533.8203125,
          7172.39208984375,
          6292.423828125,
          6605.875,
          6637.65771484375,
          6510.2060546875,
          6854.576171875,
          6636.66064453125,
          6614.5869140625,
          6623.3359375
         ]
        },
        {
         "line": {
          "color": "rgb(66, 244, 155)",
          "width": 2
         },
         "mode": "lines",
         "name": "True labels",
         "type": "scatter",
         "uid": "57197f26-cc79-11e8-b48b-88e9fe554462",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "y": [
          6529.59,
          6597.55,
          6639.14,
          6673.5,
          6856.93,
          6773.88,
          6741.75,
          6329.95,
          6394.71,
          6228.81,
          6238.05,
          6276.12,
          6359.64,
          6741.75,
          7321.04,
          7370.78,
          7466.86,
          7354.13,
          7419.29,
          7418.49,
          7711.11,
          8424.27,
          8181.39,
          7951.58,
          8165.01,
          8192.15,
          8218.46,
          8180.48,
          7780.44,
          7624.91,
          7567.15,
          7434.39,
          7032.85,
          7068.48,
          6951.8,
          6753.12,
          6305.8,
          6568.23,
          6184.71,
          6295.73,
          6322.69,
          6297.57,
          6199.71,
          6308.52,
          6334.73,
          6580.63,
          6423.76,
          6506.07,
          6308.53,
          6488.76,
          6376.71,
          6534.88,
          6719.96,
          6763.19,
          6707.26,
          6884.64,
          7096.28,
          7047.16,
          6978.23,
          7037.58,
          7193.25,
          7272.72,
          7260.06,
          7361.66,
          6792.83,
          6529.17,
          6467.07,
          6225.98,
          6300.86,
          6329.7,
          6321.2,
          6351.8,
          6517.31,
          6512.71,
          6543.2,
          6517.18,
          6281.2,
          6371.3,
          6398.54,
          6519.67,
          6734.95,
          6721.98,
          6710.63,
          6595.41,
          6446.47,
          6495,
          6676.75,
          6644.13
         ]
        }
       ],
       "layout": {
        "title": "Comparison of true prices (on the test dataset) with prices our model predicted",
        "xaxis": {
         "title": "Day number"
        },
        "yaxis": {
         "title": "Price, USD"
        }
       }
      },
      "text/html": [
       "<div id=\"708fe8bc-b4b3-4a0f-b235-5856191961f0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"708fe8bc-b4b3-4a0f-b235-5856191961f0\", [{\"line\": {\"color\": \"rgb(244, 146, 65)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Predicted labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6456.771484375, 6424.13671875, 6517.5244140625, 6936.06494140625, 6485.68017578125, 6791.0302734375, 6637.7724609375, 6521.81494140625, 6342.8837890625, 6334.62939453125, 6224.375, 6325.57763671875, 6491.7041015625, 6973.90380859375, 7391.3720703125, 6930.064453125, 7143.38671875, 7058.1298828125, 6761.75634765625, 7731.9921875, 7907.83740234375, 7899.44873046875, 7989.5302734375, 8015.7314453125, 7985.0390625, 7662.419921875, 8595.5615234375, 7201.33984375, 7645.79931640625, 7593.3330078125, 7552.46875, 7604.25, 7605.9609375, 7302.384765625, 6681.13330078125, 6676.93701171875, 6412.0966796875, 6479.91259765625, 7074.13134765625, 6929.82666015625, 6565.21142578125, 6595.8447265625, 6345.86083984375, 6301.97998046875, 6463.68115234375, 6374.60791015625, 6362.31201171875, 6333.83349609375, 6286.84326171875, 6575.18115234375, 6340.57763671875, 6503.28125, 6539.2021484375, 6708.72216796875, 7365.0322265625, 7660.24462890625, 6942.607421875, 6798.92919921875, 7132.77197265625, 7128.7861328125, 7284.46484375, 7027.89013671875, 6999.884765625, 6533.0302734375, 6629.63037109375, 6635.30810546875, 6346.6162109375, 6574.82568359375, 6565.30419921875, 6513.51708984375, 6523.791015625, 6801.767578125, 6534.22705078125, 6660.04541015625, 6705.7978515625, 6729.48681640625, 6834.14013671875, 6440.5791015625, 6533.8203125, 7172.39208984375, 6292.423828125, 6605.875, 6637.65771484375, 6510.2060546875, 6854.576171875, 6636.66064453125, 6614.5869140625, 6623.3359375], \"type\": \"scatter\", \"uid\": \"571f05f4-cc79-11e8-8185-88e9fe554462\"}, {\"line\": {\"color\": \"rgb(66, 244, 155)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"True labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6529.59, 6597.55, 6639.14, 6673.5, 6856.93, 6773.88, 6741.75, 6329.95, 6394.71, 6228.81, 6238.05, 6276.12, 6359.64, 6741.75, 7321.04, 7370.78, 7466.86, 7354.13, 7419.29, 7418.49, 7711.11, 8424.27, 8181.39, 7951.58, 8165.01, 8192.15, 8218.46, 8180.48, 7780.44, 7624.91, 7567.15, 7434.39, 7032.85, 7068.48, 6951.8, 6753.12, 6305.8, 6568.23, 6184.71, 6295.73, 6322.69, 6297.57, 6199.71, 6308.52, 6334.73, 6580.63, 6423.76, 6506.07, 6308.53, 6488.76, 6376.71, 6534.88, 6719.96, 6763.19, 6707.26, 6884.64, 7096.28, 7047.16, 6978.23, 7037.58, 7193.25, 7272.72, 7260.06, 7361.66, 6792.83, 6529.17, 6467.07, 6225.98, 6300.86, 6329.7, 6321.2, 6351.8, 6517.31, 6512.71, 6543.2, 6517.18, 6281.2, 6371.3, 6398.54, 6519.67, 6734.95, 6721.98, 6710.63, 6595.41, 6446.47, 6495.0, 6676.75, 6644.13], \"type\": \"scatter\", \"uid\": \"571f071e-cc79-11e8-b957-88e9fe554462\"}], {\"title\": \"Comparison of true prices (on the test dataset) with prices our model predicted\", \"xaxis\": {\"title\": \"Day number\"}, \"yaxis\": {\"title\": \"Price, USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"708fe8bc-b4b3-4a0f-b235-5856191961f0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"708fe8bc-b4b3-4a0f-b235-5856191961f0\", [{\"line\": {\"color\": \"rgb(244, 146, 65)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Predicted labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6456.771484375, 6424.13671875, 6517.5244140625, 6936.06494140625, 6485.68017578125, 6791.0302734375, 6637.7724609375, 6521.81494140625, 6342.8837890625, 6334.62939453125, 6224.375, 6325.57763671875, 6491.7041015625, 6973.90380859375, 7391.3720703125, 6930.064453125, 7143.38671875, 7058.1298828125, 6761.75634765625, 7731.9921875, 7907.83740234375, 7899.44873046875, 7989.5302734375, 8015.7314453125, 7985.0390625, 7662.419921875, 8595.5615234375, 7201.33984375, 7645.79931640625, 7593.3330078125, 7552.46875, 7604.25, 7605.9609375, 7302.384765625, 6681.13330078125, 6676.93701171875, 6412.0966796875, 6479.91259765625, 7074.13134765625, 6929.82666015625, 6565.21142578125, 6595.8447265625, 6345.86083984375, 6301.97998046875, 6463.68115234375, 6374.60791015625, 6362.31201171875, 6333.83349609375, 6286.84326171875, 6575.18115234375, 6340.57763671875, 6503.28125, 6539.2021484375, 6708.72216796875, 7365.0322265625, 7660.24462890625, 6942.607421875, 6798.92919921875, 7132.77197265625, 7128.7861328125, 7284.46484375, 7027.89013671875, 6999.884765625, 6533.0302734375, 6629.63037109375, 6635.30810546875, 6346.6162109375, 6574.82568359375, 6565.30419921875, 6513.51708984375, 6523.791015625, 6801.767578125, 6534.22705078125, 6660.04541015625, 6705.7978515625, 6729.48681640625, 6834.14013671875, 6440.5791015625, 6533.8203125, 7172.39208984375, 6292.423828125, 6605.875, 6637.65771484375, 6510.2060546875, 6854.576171875, 6636.66064453125, 6614.5869140625, 6623.3359375], \"type\": \"scatter\", \"uid\": \"571f05f4-cc79-11e8-8185-88e9fe554462\"}, {\"line\": {\"color\": \"rgb(66, 244, 155)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"True labels\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"y\": [6529.59, 6597.55, 6639.14, 6673.5, 6856.93, 6773.88, 6741.75, 6329.95, 6394.71, 6228.81, 6238.05, 6276.12, 6359.64, 6741.75, 7321.04, 7370.78, 7466.86, 7354.13, 7419.29, 7418.49, 7711.11, 8424.27, 8181.39, 7951.58, 8165.01, 8192.15, 8218.46, 8180.48, 7780.44, 7624.91, 7567.15, 7434.39, 7032.85, 7068.48, 6951.8, 6753.12, 6305.8, 6568.23, 6184.71, 6295.73, 6322.69, 6297.57, 6199.71, 6308.52, 6334.73, 6580.63, 6423.76, 6506.07, 6308.53, 6488.76, 6376.71, 6534.88, 6719.96, 6763.19, 6707.26, 6884.64, 7096.28, 7047.16, 6978.23, 7037.58, 7193.25, 7272.72, 7260.06, 7361.66, 6792.83, 6529.17, 6467.07, 6225.98, 6300.86, 6329.7, 6321.2, 6351.8, 6517.31, 6512.71, 6543.2, 6517.18, 6281.2, 6371.3, 6398.54, 6519.67, 6734.95, 6721.98, 6710.63, 6595.41, 6446.47, 6495.0, 6676.75, 6644.13], \"type\": \"scatter\", \"uid\": \"571f071e-cc79-11e8-b957-88e9fe554462\"}], {\"title\": \"Comparison of true prices (on the test dataset) with prices our model predicted\", \"xaxis\": {\"title\": \"Day number\"}, \"yaxis\": {\"title\": \"Price, USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y1 = Y_pred.reshape(-1,)[2:]\n",
    "y2 = Y_test.reshape(-1,)[0:-2]\n",
    "trace1 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_pred), 1),\n",
    "    y = y1,\n",
    "    mode = 'lines',\n",
    "    name = 'Predicted labels',\n",
    "    line = dict(color=('rgb(244, 146, 65)'), width=2)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_test), 1),\n",
    "    y = y2,\n",
    "    mode = 'lines',\n",
    "    name = 'True labels',\n",
    "    line = dict(color=('rgb(66, 244, 155)'), width=2)\n",
    ")\n",
    "\n",
    "layout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted',\n",
    "             xaxis = dict(title = 'Day number'), yaxis = dict(title = 'Price, USD'))\n",
    "fig = dict(data=[trace1, trace2], layout=layout)\n",
    "py.iplot(fig, filename='results_demonstrating0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('XGB.csv', Y_pred.reshape(-1,1), delimiter=',',  fmt='%1.10e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
